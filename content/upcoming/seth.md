+++
title = 'June 26: Professor Seth Lazar (Australian National University)'
date = 2025-06-26T10:00:10+01:00
draft = false
hideMeta = true
summary = "Something on AI ethics"
weight = 11
+++
 

#### Title
On AI Personhood Without Sentience

#### Abstract
Rapid progress in AI research means that highly capable AI agents are on the horizon. So capable, in fact, that once-speculative questions about the possibility of AI agents having moral and political status must now be addressed with some urgency. Many think our answers to these questions will turn on whether such agents will be sentient. In this paper, we argue that even non-sentient agents could potentially satisfy one prominent and plausible criterion for political personhood—John Rawls’ ‘Political Conception of the Person’ (PCP). We argue that the PCP does not—and should not—presuppose sentience. And we argue that in the near term it will indeed be possible to design AI agents that are persons according to the PCP.

We consider two possible upshots. One takes the conclusion as a reductio: the PCP should be either revised or rejected so that near-term non-sentient AI agents are definitively excluded from political status. The other acknowledges that AI agents that satisfy the PCP would be a significant change in the moral landscape—demanding not so much an expansion of the moral circle as drawing a new moral Venn diagram. We show that egalitarian political philosophy in particular, which has hitherto benefited from humanity’s relative uniformity, would have to be rethought for societies that include both natural and radically different AI persons.
 

#### About [Seth](https://sethlazar.org)

Seth Lazar is Professor of Philosophy at the Australian National University, a Distinguished Research Fellow of the University of Oxford Institute for Ethics in AI, a fellow of the Carnegie Endowment for International Peace, and a Senior AI Advisor to the Knight First Amendment Institute at Columbia University. He founded the Machine Intelligence and Normative Theory (MINT) Lab, where he leads research projects in philosophy of computing and AI safety.



