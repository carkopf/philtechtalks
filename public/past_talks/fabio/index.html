<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>September 26: Dr. Fabio Tollon and Dr. Enrico Galvagni (Edinburgh) | Phil.Tech.Talks</title>
<meta name=keywords content><meta name=description content="Conceptual engineering and responsibility"><meta name=author content><link rel=canonical href=https://philtechtalks.netlify.app/past_talks/fabio/><meta name=google-site-verification content="G-ENE3M094RN"><link crossorigin=anonymous href=/assets/css/stylesheet.9c8530f2c62fb1bbcb8855a8f50041f6c4f663711d26b31c460c62ec78068a0a.css integrity="sha256-nIUw8sYvsbvLiFWo9QBB9sT2Y3EdJrMcRgxi7HgGigo=" rel="preload stylesheet" as=style><link rel=icon href=https://philtechtalks.netlify.app/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://philtechtalks.netlify.app/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://philtechtalks.netlify.app/favicon-32x32.png><link rel=apple-touch-icon href=https://philtechtalks.netlify.app/apple-touch-icon.png><link rel=mask-icon href=https://philtechtalks.netlify.app/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://philtechtalks.netlify.app/past_talks/fabio/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-ENE3M094RN"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ENE3M094RN")}</script><meta property="og:title" content="September 26: Dr. Fabio Tollon and Dr. Enrico Galvagni (Edinburgh)"><meta property="og:description" content="Conceptual engineering and responsibility"><meta property="og:type" content="article"><meta property="og:url" content="https://philtechtalks.netlify.app/past_talks/fabio/"><meta property="article:section" content="past_talks"><meta property="article:published_time" content="2025-09-26T10:00:10+01:00"><meta property="article:modified_time" content="2025-09-26T10:00:10+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="September 26: Dr. Fabio Tollon and Dr. Enrico Galvagni (Edinburgh)"><meta name=twitter:description content="Conceptual engineering and responsibility"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Past_talks","item":"https://philtechtalks.netlify.app/past_talks/"},{"@type":"ListItem","position":2,"name":"September 26: Dr. Fabio Tollon and Dr. Enrico Galvagni (Edinburgh)","item":"https://philtechtalks.netlify.app/past_talks/fabio/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"September 26: Dr. Fabio Tollon and Dr. Enrico Galvagni (Edinburgh)","name":"September 26: Dr. Fabio Tollon and Dr. Enrico Galvagni (Edinburgh)","description":"Conceptual engineering and responsibility","keywords":[],"articleBody":"Title Engineering Responsibility in the Age of AI: Amelioration or Preservation?\nAbstract Responsibility gaps arise when harm is caused by autonomous systems and we are unable to appropriately assign moral responsibility for that harm. This occurs because (i) no human being can be held accountable given the autonomous nature of the system that created the harm; and (ii) the system itself lacks the relevant features to be considered a responsible agent. Neither the humans who developed and deployed the system nor the machines themselves are responsible. Hence, the gap arises: there is no one to be held responsible for the harm, yet (unlike cases of natural disasters) we have the intuition that someone should be responsible. In this paper, we tap into the literature on conceptual engineering to explore two strategies regarding this issue. On the one hand, we can identify the risks of gaps and attempt to ameliorate the concept in the hope of removing them. On the other hand, we can highlight the risks of conceptual revision and aim to preserve our current concept as it is. We argue that conceptual preservation is an underutilized yet promising strategy in the case of AI-enabled responsibility gaps, and show how its theoretical upsides play out in practice.\nAbout Fabio Fabio is a philosopher specializing in the interplay between technology, ethics of artificial intelligence, moral responsibility, and free will.\nSince completing his PhD at Bielefeld in 2023, Fabio has been working as a postdoctoral researcher at the University of Edinburgh.\nAbout Enrico Enrico‚Äôs research interests include Early Modern Philosophy (esp. British Moralists), Virtue Ethics, Enlightenment Studies, Ethics, and its History.\nHe holds a Ph.D. from the University of St Andrews (Scotland). For the 2022 Fall term, he was a visiting doctoral researcher at NYU. He has also spent time as a DAAD research fellow at the University of Mainz, the G√∂ttingen Institute of Advanced Study and the University of Cologne.\n","wordCount":"319","inLanguage":"en","datePublished":"2025-09-26T10:00:10+01:00","dateModified":"2025-09-26T10:00:10+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://philtechtalks.netlify.app/past_talks/fabio/"},"publisher":{"@type":"Organization","name":"Phil.Tech.Talks","logo":{"@type":"ImageObject","url":"https://philtechtalks.netlify.app/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://philtechtalks.netlify.app/ accesskey=h title="Phil.Tech.Talks (Alt + H)">Phil.Tech.Talks</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://philtechtalks.netlify.app/past_talks/ title="Past talks"><span>Past talks</span></a></li><li><a href=https://philtechtalks.netlify.app/workshop/ title=Workshop><span>Workshop</span></a></li><li><a href=https://philtechtalks.netlify.app/contact/ title="Join in"><span>Join in</span></a></li><li><a href=https://philtechtalks.netlify.app/search/ title="üîç (Alt + /)" accesskey=/><span>üîç</span></a></li></ul><div class=juelich-logo><a href=https://www.fz-juelich.de/en target=_blank title="Forschungszentrum J√ºlich"><img src=/juelich-logo.svg alt="Forschungszentrum J√ºlich" height=140></a></div></nav></header><style>.juelich-logo{display:flex;align-items:center;margin-left:auto;padding-left:20px}.juelich-logo img{height:140px;width:auto;opacity:.85;transition:opacity .2s,transform .2s ease}.juelich-logo img:hover{opacity:1;transform:scale(1.05)}@media screen and (max-width:768px){.juelich-logo{display:none}}</style><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">September 26: Dr. Fabio Tollon and Dr. Enrico Galvagni (Edinburgh)</h1></header><div class=post-content><h4 id=title>Title<a hidden class=anchor aria-hidden=true href=#title>#</a></h4><p>Engineering Responsibility in the Age of AI: Amelioration or Preservation?</p><h4 id=abstract>Abstract<a hidden class=anchor aria-hidden=true href=#abstract>#</a></h4><p>Responsibility gaps arise when harm is caused by autonomous systems and we are unable to appropriately assign moral responsibility for that harm. This occurs because (i) no human being can be held accountable given the autonomous nature of the system that created the harm; and (ii) the system itself lacks the relevant features to be considered a responsible agent. Neither the humans who developed and deployed the system nor the machines themselves are responsible. Hence, the gap arises: there is no one to be held responsible for the harm, yet (unlike cases of natural disasters) we have the intuition that someone should be responsible. In this paper, we tap into the literature on conceptual engineering to explore two strategies regarding this issue. On the one hand, we can identify the risks of gaps and attempt to ameliorate the concept in the hope of removing them. On the other hand, we can highlight the risks of conceptual revision and aim to preserve our current concept as it is. We argue that conceptual preservation is an underutilized yet promising strategy in the case of AI-enabled responsibility gaps, and show how its theoretical upsides play out in practice.</p><h4 id=about-fabiohttpsfabiotollonwixsitecomfabiotollonabout>About <a href=https://fabiotollon.wixsite.com/fabiotollon/about>Fabio</a><a hidden class=anchor aria-hidden=true href=#about-fabiohttpsfabiotollonwixsitecomfabiotollonabout>#</a></h4><p>Fabio is a philosopher specializing in the interplay between technology, ethics of artificial intelligence, moral responsibility, and free will.</p><p>Since completing his PhD at Bielefeld in 2023, Fabio has been working as a postdoctoral researcher at the University of Edinburgh.</p><h4 id=about-enricohttpsedwebprofilesedacukprofileenricogalvagni>About <a href=https://edwebprofiles.ed.ac.uk/profile/enricogalvagni>Enrico</a><a hidden class=anchor aria-hidden=true href=#about-enricohttpsedwebprofilesedacukprofileenricogalvagni>#</a></h4><p>Enrico&rsquo;s research interests include Early Modern Philosophy (esp. British Moralists), Virtue Ethics, Enlightenment Studies, Ethics, and its History.</p><p>He holds a Ph.D. from the University of St Andrews (Scotland). For the 2022 Fall term, he was a visiting doctoral researcher at NYU. He has also spent time as a DAAD research fellow at the University of Mainz, the G√∂ttingen Institute of Advanced Study and the University of Cologne.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>Site maintained by <a href=mailto:charles.rathkopf@gmail.com>Charles Rathkopf</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>